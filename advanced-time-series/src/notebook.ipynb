{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Econometric Time Series - Group Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "os.chdir('c:/Users/pelpi/Documents/VSCode repositories/aets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"assignment/data.csv\", sep=';', decimal=',')\n",
    "\n",
    "# Convert data to float\n",
    "data = data.astype({'PCE':'float','PAYEMS':'float', 'IPMAN' : 'float'})\n",
    "\n",
    "# Split data in train and test set\n",
    "train_data = data[:189]\n",
    "test_data = data[189:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Markov Switching Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_pdf(x, mean=0, sd=1):\n",
    "    ''' Method that returns the pdf of a normal distribution'''\n",
    "    \n",
    "    return 1 / (sd * math.sqrt(2*math.pi)) * math.exp(-0.5 * ((x - mean)/sd) ** 2)\n",
    "\n",
    "def hamilton_filter(params, data, initial_ksi_1 = 0):\n",
    "    '''Method that performs a hamilton filter algorithm'''\n",
    "    \n",
    "    if not len(params) in [6, 7]:\n",
    "        raise Exception('''Please provide either 6 or 7 parameters in params:\n",
    "                        mu1\n",
    "                        mu2\n",
    "                        sigma1\n",
    "                        sigma2\n",
    "                        p11\n",
    "                        p12\n",
    "                        (initial_ksi_1)''')\n",
    "    \n",
    "    # Extract the parameters that are provided\n",
    "    mu1, mu2, sigma1, sigma2, p11, p22 = params[:6]\n",
    "    \n",
    "    if len(params) == 7:\n",
    "        initial_ksi_1 = params[6]\n",
    "        \n",
    "    filtered = list()\n",
    "    predicted = list()\n",
    "    \n",
    "    # Set the inital ksi \n",
    "    predicted_ksi = np.array([[initial_ksi_1],[1 - initial_ksi_1]])\n",
    "    \n",
    "    # Set up the transition matrix\n",
    "    P = np.array([[p11, 1 - p22],\n",
    "                [1 - p11, p22]])\n",
    "    \n",
    "    # Initialize the log densities\n",
    "    log_densities = list()\n",
    "    \n",
    "    # Loop over the data\n",
    "    for y_t in data:\n",
    "        \n",
    "        # Calculate density\n",
    "        density = normal_pdf(y_t, mu1, sigma1) * predicted_ksi[0] + normal_pdf(y_t, mu2, sigma2) * predicted_ksi[1]\n",
    "        log_densities.append(np.log(density))\n",
    "        \n",
    "        # Hamilton Update Step\n",
    "        numerator = np.multiply(np.array([[normal_pdf(y_t, mu1, sigma1)],[normal_pdf(y_t, mu2, sigma2)]]), predicted_ksi)\n",
    "        denominator = np.array([1,1]).dot(numerator)\n",
    "\n",
    "        filtered_ksi = numerator / denominator\n",
    "        \n",
    "        # Save filtered and predicted ksi's\n",
    "        filtered.append(filtered_ksi)\n",
    "        predicted.append(predicted_ksi)\n",
    "        \n",
    "        # Hamilton Prediction Step\n",
    "        predicted_ksi = P.dot(filtered_ksi)\n",
    "    \n",
    "    # Return the negative log likelihood, filtered ksi and predicted ksi\n",
    "    return [filtered, predicted, log_densities]\n",
    "\n",
    "def negative_log_likelihood(params, data, initial_ksi_1 = 0):\n",
    "    '''Methot that returns the negative log likelihood of a hamilton filter'''\n",
    "    \n",
    "    _, _, log_densities = hamilton_filter(params, data, initial_ksi_1)\n",
    "\n",
    "    # Return negative log likelihood\n",
    "    return -1*sum(log_densities)\n",
    "    \n",
    "# Initial Parameters\n",
    "y = train_data[\"IPMAN\"]\n",
    "\n",
    "mu1 = y.mean()\n",
    "mu2 = y.mean()\n",
    "sigma1 = 0.5*y.std()\n",
    "sigma2 = 1.5*y.std()\n",
    "p11 = 0.8\n",
    "p22 = 0.8\n",
    "initial_ksi_1 = (1-p22)/(2-p11-p22)\n",
    "\n",
    "#bounds = ((None, None), (None, None), (0, None), (0, None), (0, 1), (0, 1))\n",
    "#bounds = ((None, None), (None, None), (0, None), (0, None), (0, 1), (0, 1), (0, 1))\n",
    "\n",
    "x0 = np.array([mu1, mu2, sigma1, sigma2, p11, p22])\n",
    "#x0 = np.array([mu1, mu2, sigma1, sigma2, p11, p22, initial_ksi_1])\n",
    "args = (y, initial_ksi_1)\n",
    "\n",
    "mle = optimize.minimize(negative_log_likelihood, x0=x0, args=args, method='Nelder-Mead', options = {'maxiter': 1000})\n",
    "#mle = optimize.minimize(hamilton_filter, x0=x0, args=args, method='Nelder-Mead', options = {'maxiter': 1000}, bounds=bounds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Parameters\n",
    "y = train_data[\"IPMAN\"]\n",
    "mu1 = y.mean()\n",
    "mu2 = y.mean()\n",
    "sigma1 = 0.5*y.std()\n",
    "sigma2 = 1.5*y.std()\n",
    "p11 = 0.8\n",
    "p22 = 0.8\n",
    "initial_ksi_1_list = [1, 0, (1-p22)/(2-p11-p22)]\n",
    "\n",
    "# Initialize result dataframe\n",
    "columns = ['loglikelihood', 'mu1', 'mu2', 'sigma1', 'sigma2', 'p11', 'p22', 'long_run_mean']\n",
    "result = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Loop over all intitial ksi_1s\n",
    "for index, ksi_1 in enumerate(initial_ksi_1_list):\n",
    "    \n",
    "    # Initial parameters\n",
    "    x0 = np.array([mu1, mu2, sigma1, sigma2, p11, p22])\n",
    "    \n",
    "    # Additional arguments\n",
    "    args = (y, ksi_1)\n",
    "    \n",
    "    mle = optimize.minimize(negative_log_likelihood, x0=x0, args=args, method='Nelder-Mead', options = {'maxiter': 1000})\n",
    "    \n",
    "    row = {'loglikelihood': -1*mle.fun, 'mu1': mle.x[0], 'mu2': mle.x[1], 'sigma1': mle.x[2], 'sigma2': mle.x[3], 'p11': mle.x[4], 'p22': mle.x[5], 'long_run_mean': (1-mle.x[5])/(2-mle.x[4]-mle.x[5])}\n",
    "    \n",
    "    result.loc[index, :] = row\n",
    "    \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Parameters\n",
    "mu1 = y.mean()\n",
    "mu2 = y.mean()\n",
    "sigma1 = 0.5*y.std()\n",
    "sigma2 = 1.5*y.std()\n",
    "p11 = 0.8\n",
    "p22 = 0.8\n",
    "x0 = np.array([mu1, mu2, sigma1, sigma2, p11, p22])\n",
    "\n",
    "# Arguments\n",
    "y = train_data[\"IPMAN\"]\n",
    "initial_ksi_1 = 1\n",
    "args = (y, initial_ksi_1)\n",
    "\n",
    "# Obtain optimal values\n",
    "mle = optimize.minimize(negative_log_likelihood, x0=x0, args=args, method='Nelder-Mead', options = {'maxiter': 1000})\n",
    "hamilton = hamilton_filter(mle.x, y, initial_ksi_1)\n",
    "\n",
    "# Set up optimal transition matrix\n",
    "p11_opt = mle.x[4]\n",
    "p22_opt = mle.x[5]\n",
    "P = np.array([[p11_opt, 1 - p22_opt],\n",
    "                [1 - p11_opt, p22_opt]])\n",
    "\n",
    "# Obtain forecasted ksi\n",
    "forecasted_ksi = list()\n",
    "forecasted_ksi.append(P.dot(hamilton[0][-1]))\n",
    "\n",
    "for h in range(13):\n",
    "    forecasted_ksi.append(P.dot(forecasted_ksi[-1]))\n",
    "\n",
    "# Obtain forecasted values\n",
    "mu1_opt = mle.x[0]\n",
    "mu2_opt = mle.x[1]\n",
    "mu_opt = np.array([[mu1_opt], [mu2_opt]])\n",
    "forecasted_y = [np.array([1, 1])@(mu_opt * ksi) for ksi in forecasted_ksi]\n",
    "\n",
    "forecasted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Predicted\", \"Actual\", \"Error\"]\n",
    "forecast_results = pd.DataFrame(columns=column_names)\n",
    "\n",
    "forecast_results[\"Predicted\"] = [el[0] for el in forecasted_y]\n",
    "forecast_results[\"Actual\"] = test_data[\"IPMAN\"].values\n",
    "forecast_results[\"Error\"] = forecast_results[\"Predicted\"] - forecast_results[\"Actual\"]\n",
    "\n",
    "print(forecast_results)\n",
    "print(f'MSFE: {(forecast_results[\"Error\"] ** 2).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamilton_full = hamilton_filter(mle.x, data[\"IPMAN\"], initial_ksi_1=1)\n",
    "\n",
    "forecasted_y_expanding = [np.array([1, 1])@(mu_opt * ksi) for ksi in hamilton_full[1][-14:]]\n",
    "\n",
    "column_names = [\"Predicted\", \"Actual\", \"Error\"]\n",
    "forecast_results_expanding = pd.DataFrame(columns=column_names)\n",
    "\n",
    "forecast_results_expanding[\"Predicted\"] = [el[0] for el in forecasted_y_expanding]\n",
    "forecast_results_expanding[\"Actual\"] = test_data[\"IPMAN\"].values\n",
    "forecast_results_expanding[\"Error\"] = forecast_results_expanding[\"Predicted\"] - forecast_results_expanding[\"Actual\"]\n",
    "\n",
    "print(forecast_results_expanding)\n",
    "print(f'MSFE: {(forecast_results_expanding[\"Error\"] ** 2).mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_em(params, data, initial_ksi1 = 0, niter = 1000):\n",
    "    \n",
    "    for _ in range(niter):\n",
    "        params = markov_em_step(params, data, initial_ksi1)\n",
    "        \n",
    "    return params\n",
    "    \n",
    "\n",
    "def markov_em_step(params, data, initial_ksi_1 = 0):\n",
    "    \n",
    "    # E-step: run smoother\n",
    "    smoothed_ksi, cross_P, smoothed_initial_ksi_1 = hamilton_smoother(params, data, initial_ksi_1)\n",
    "    \n",
    "    # Extract star quantities\n",
    "    T = len(cross_P)\n",
    "    \n",
    "    p11star = [cross_P[t][0][0] for t in range(T)]\n",
    "    p12star = [cross_P[t][0][1] for t in range(T)]\n",
    "    p1star =  [p11star[t] + p12star[t] for t in range(T)]\n",
    "    p21star = [cross_P[t][1][0] for t in range(T)]\n",
    "    p22star = [cross_P[t][1][1] for t in range(T)]\n",
    "    p2star  = [p21star[t] + p22star[t] for t in range(T)]\n",
    "    \n",
    "    # M-step: use analytic formulas\n",
    "    p11_new = sum(p11star) / (smoothed_initial_ksi_1 + sum(p1star[:-1]))\n",
    "    p22_new = sum(p22star) / ((1-smoothed_initial_ksi_1) + sum(p2star[:-1]))\n",
    "    mu1_new = sum(p1star * data) / sum(p1star)\n",
    "    mu2_new = sum(p2star * data) / sum(p2star)\n",
    "    sigma1_new = math.sqrt(sum( p1star * (y-mu1) ** 2) / sum(p1star))\n",
    "    sigma2_new = math.sqrt(sum( p2star * (y-mu2) ** 2) / sum(p2star))\n",
    "    \n",
    "    params_new = np.array([mu1_new, mu2_new, sigma1_new, sigma2_new, p11_new, p22_new])\n",
    "    \n",
    "    if len(params) == 7:\n",
    "        params_new = np.concatenate((params_new, np.array([smoothed_initial_ksi_1])))\n",
    "    \n",
    "    return params_new\n",
    "    \n",
    "\n",
    "def kim_smoother(filtered_ksi, predicted_ksi, P):\n",
    "    \n",
    "    # Set up last value of smoothed_ksi\n",
    "    T = len(filtered_ksi)\n",
    "    last_predicted_ksi = P @ filtered_ksi[T-1]\n",
    "    smoothed_ksi = [filtered_ksi[T-1]*P.T @ (last_predicted_ksi / last_predicted_ksi)] * (T+1)\n",
    "    \n",
    "    # Iterate backwards to smooth the ksi\n",
    "    for t in range(T-2, -1, -1):\n",
    "        \n",
    "        smoothed_ksi[t] = filtered_ksi[t]* P.T @ (smoothed_ksi[t+1] / predicted_ksi[t+1])\n",
    "\n",
    "    # Calculate P cross terms\n",
    "    cross_P = [P * (smoothed_ksi[t] @ filtered_ksi[t-1].T) / (predicted_ksi[t] @ np.ones(2).reshape(1,2)) for t in range(T)]\n",
    "    \n",
    "    return smoothed_ksi, cross_P\n",
    "\n",
    "def hamilton_smoother(params, data, initial_ksi_1 = 0):\n",
    "    # Set up transition matrix\n",
    "    _, _, _, _, p11, p22 = params[:6]\n",
    "    P = np.array([[p11, 1 - p22], [1 - p11, p22]])\n",
    "\n",
    "    # Run hamilton filter forwards\n",
    "    filtered_ksi, predicted_ksi, _ = hamilton_filter(params, data, initial_ksi_1)\n",
    "    \n",
    "    # Run Kim smoother backwards\n",
    "    smoothed_ksi, cross_P = kim_smoother(filtered_ksi, predicted_ksi, P)\n",
    "    \n",
    "    # Get smoothed initial_ksi_1\n",
    "    if len(params) == 7:\n",
    "        smoothed_initial_ksi = params[6] * (P.T @ (smoothed_ksi[0] / predicted_ksi[0]))\n",
    "        smoothed_initial_ksi_1 = smoothed_initial_ksi[0][0]\n",
    "    else:\n",
    "        smoothed_initial_ksi_1 = initial_ksi_1\n",
    "    \n",
    "    return smoothed_ksi, cross_P, smoothed_initial_ksi_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "y = train_data[\"IPMAN\"]\n",
    "\n",
    "# Initial Parameters\n",
    "mu1 = y.mean()\n",
    "mu2 = y.mean()\n",
    "sigma1 = 0.5*y.std()\n",
    "sigma2 = 1.5*y.std()\n",
    "p11 = 0.8\n",
    "p22 = 0.8\n",
    "initial_ksi_1 = 0.1\n",
    "x0 = np.array([mu1, mu2, sigma1, sigma2, p11, p22, initial_ksi_1])\n",
    "\n",
    "em_params = markov_em(x0, y, niter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: State Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_demean = train_data.copy()\n",
    "test_data_demean = test_data.copy()\n",
    "\n",
    "pce_mean = train_data_demean[\"PCE\"].mean()\n",
    "payems_mean = train_data_demean[\"PAYEMS\"].mean()\n",
    "ipman_mean = train_data_demean[\"IPMAN\"].mean()\n",
    "\n",
    "train_data_demean[\"PCE\"] = train_data_demean[\"PCE\"] - pce_mean\n",
    "train_data_demean[\"PAYEMS\"] = train_data_demean[\"PAYEMS\"] - payems_mean\n",
    "train_data_demean[\"IPMAN\"] = train_data_demean[\"IPMAN\"] - ipman_mean\n",
    "\n",
    "test_data_demean[\"PCE\"] = test_data_demean[\"PCE\"] - pce_mean\n",
    "test_data_demean[\"PAYEMS\"] = test_data_demean[\"PAYEMS\"] - payems_mean\n",
    "test_data_demean[\"IPMAN\"] = test_data_demean[\"IPMAN\"] - ipman_mean\n",
    "\n",
    "variables = [\"PCE\", \"PAYEMS\", \"IPMAN\"]\n",
    "means = {\"PCE\": pce_mean, \"PAYEMS\": payems_mean, \"IPMAN\": ipman_mean}\n",
    "\n",
    "test_data_demean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KF_LL(Q, R, F , y, ksi0, P0):\n",
    "    '''Method that performs a Kalman filter algorithm'''\n",
    "    \n",
    "    # Extract length of the data\n",
    "    T = len(y)\n",
    "    \n",
    "    predictedksi = np.zeros(T)\n",
    "    predictedP = np.zeros(T)\n",
    "    \n",
    "    ksi = np.zeros(T)\n",
    "    P = np.zeros(T)\n",
    "    \n",
    "    # The first prediction is based on xi0 and P0\n",
    "    predictedksi[0] = F * ksi0\n",
    "    predictedP[0] = F * P0 * F + Q\n",
    "    \n",
    "    # The first updating step\n",
    "    ksi[0] = predictedksi[0] + predictedP[0] * 1 / (predictedP[0] + R) * (y[0] - predictedksi[0])\n",
    "    P[0] = predictedP[0] - predictedP[0] * 1 / (predictedP[0] + R) * predictedP[0]\n",
    "    \n",
    "    # The Kalman filter\n",
    "    for t in range(1, T):\n",
    "        # Further predictions are based on previous updates\n",
    "        predictedksi[t] = F * ksi[t-1]\n",
    "        predictedP[t] = F * P[t-1] * F + Q\n",
    "    \n",
    "        # Update\n",
    "        ksi[t] = predictedksi[t] + predictedP[t] * 1 / (predictedP[t] + R) * (y[t] - predictedksi[t])\n",
    "        P[t] = predictedP[t] - predictedP[t] * 1 / (predictedP[t] + R) * predictedP[t]\n",
    "    \n",
    "    return ksi, P, predictedksi, predictedP\n",
    "\n",
    "def negative_log_likelihood_state_space(params, data, ksi0, P0):\n",
    "    '''Method that calculates the negative log likelihood of the state space algorithm'''\n",
    "    \n",
    "    Q, R, F = params\n",
    "    \n",
    "    _, _, predicted_ksi, predicted_P = KF_LL(Q, R, F, data, ksi0, P0)\n",
    "    \n",
    "    log_likelihoods = list()\n",
    "    \n",
    "    for ksi, P, y in zip(predicted_ksi, predicted_P, data):\n",
    "        var = P + R\n",
    "        mu = ksi\n",
    "        LL = np.log(max(normal_pdf(y, mu, math.sqrt(var)), 10 ** -5))\n",
    "        log_likelihoods.append(LL)\n",
    "    \n",
    "    return -1*sum(log_likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [train_data_demean[\"PCE\"], train_data_demean[\"PAYEMS\"], train_data_demean[\"IPMAN\"]]\n",
    "\n",
    "# Arguments\n",
    "ksi0 = 0\n",
    "P0 = 10 ** 6\n",
    "\n",
    "# Initial parameters\n",
    "Q0 = 0.1\n",
    "R0 = 0.3\n",
    "F0 = 0.8\n",
    "x0 = (Q0, R0, F0)\n",
    "bounds = ((0, None), (0, None), (None, None))\n",
    "\n",
    "\n",
    "columns = ['loglikelihood', 'Q', 'R', 'F', 'steady_state_value']\n",
    "result = pd.DataFrame(columns=columns)\n",
    "\n",
    "for index, y_i in enumerate(y):\n",
    "    \n",
    "    args = (y_i, ksi0, P0)\n",
    "    \n",
    "    mle = optimize.minimize(negative_log_likelihood_state_space, x0=x0, args=args, method='Nelder-Mead', bounds=bounds, options = {'maxiter': 1000})\n",
    "    \n",
    "    Q_opt  = mle.x[0]\n",
    "    R_opt = mle.x[1]\n",
    "    F_opt = mle.x[2]\n",
    "\n",
    "    # Calulate steady state\n",
    "    a = 1\n",
    "    b = -(F_opt ** 2 + F_opt ** 2 * R_opt + Q_opt - R_opt)\n",
    "    c = -1*R_opt*Q_opt\n",
    "    try:\n",
    "        P_bar = (-b + math.sqrt(b ** 2 - 4*a*c)) / (2*a)\n",
    "    except:\n",
    "        P_bar = 'NaN'\n",
    "    \n",
    "    row = {'loglikelihood': -1*mle.fun, 'Q': Q_opt, 'R': R_opt, 'F': F_opt, 'steady_state_value': P_bar}\n",
    "    \n",
    "    result.loc[index, :] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names\n",
    "column_names = [\"Predicted\", \"Actual\", \"Error\"]\n",
    "all_forecast_results = dict()\n",
    "\n",
    "# Loop over all variables\n",
    "for index, var in enumerate(variables):\n",
    "    \n",
    "    # Extract the optimal parameters and data\n",
    "    Q = result.iloc[index][\"Q\"]\n",
    "    R = result.iloc[index][\"R\"]\n",
    "    F = result.iloc[index][\"F\"]\n",
    "    y_i = train_data_demean[var]\n",
    "    \n",
    "    # Perform the kalman filter and extract ksi\n",
    "    ksi, _, _, _ = KF_LL(Q, R, F , y_i, ksi0, P0)\n",
    "    \n",
    "    # Get the forecasted y values and the actual ones\n",
    "    forecasted_y = [(F ** h) * ksi[-1] + means[var] for h in range(1, 15)]\n",
    "    actual_y = test_data_demean[var] + means[var]\n",
    "    \n",
    "    # Put the forecasts and actuals in a dataframe\n",
    "    forecast_results = pd.DataFrame(columns=column_names)\n",
    "    forecast_results[\"Predicted\"] = forecasted_y\n",
    "    forecast_results[\"Actual\"] = test_data[var].values\n",
    "    forecast_results[\"Error\"] = forecast_results[\"Predicted\"] - forecast_results[\"Actual\"]\n",
    "    all_forecast_results[var] = forecast_results\n",
    "\n",
    "    # Print the dataframe and the MSFE\n",
    "    print(f'Variable: {var}')\n",
    "    print(forecast_results)\n",
    "    print(f'MSFE: {(forecast_results[\"Error\"] ** 2).mean()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KF_LL_multi(Q, F, H , y, ksi0, P0, R = 0):\n",
    "    '''Method that performs the multivariate  Kalman Filter algorithm '''\n",
    "    \n",
    "    # Extract length of the data\n",
    "    T = len(y)\n",
    "    \n",
    "    predictedksi = [np.copy(ksi0)] * T\n",
    "    predictedP = [np.copy(P0)] * T \n",
    "    \n",
    "    ksi = [np.copy(ksi0)] * T\n",
    "    P = [np.copy(P0)] * T \n",
    "    \n",
    "    # The first prediction is based on xi0 and P0\n",
    "    predictedksi[0] = F @ ksi0\n",
    "    predictedP[0] = F @ P0 @ F.T + Q\n",
    "    \n",
    "    # The first updating step\n",
    "    \n",
    "    ksi[0] = predictedksi[0] + predictedP[0] @ H @ np.linalg.inv(H.T @ predictedP[0] @ H + R) @ (y[0] - H.T @ predictedksi[0])\n",
    "    P[0] = predictedP[0] - predictedP[0] @ H @ np.linalg.inv(H.T @ predictedP[0] @ H + R) @ H.T @ predictedP[0]\n",
    "    \n",
    "    # The Kalman filter\n",
    "    for t in range(1, T):\n",
    "        \n",
    "        # Further predictions are based on previous updates\n",
    "        predictedksi[t] = F @ ksi[t-1]\n",
    "        predictedP[t] = F @ P[t-1] @ F.T + Q\n",
    "    \n",
    "        # Update\n",
    "        ksi[t] = predictedksi[t] + predictedP[t] @ H @ np.linalg.inv(H.T @ predictedP[t] @ H + R) @ (y[t] - H.T @ predictedksi[t])\n",
    "        P[t] = predictedP[t] - predictedP[t] @ H @ np.linalg.inv(H.T @ predictedP[t] @ H + R) @ H.T @ predictedP[t]\n",
    "    \n",
    "    return ksi, P, predictedksi, predictedP\n",
    "\n",
    "\n",
    "def multivariate_normal_pdf(y, mu, Sigma):\n",
    "    '''Method that calculates the value of a multivariate normal pdf'''\n",
    "    \n",
    "    prefactor = 1 / np.sqrt(max(np.linalg.det(2 * np.pi * Sigma), 10 ** -5))\n",
    "    exponent = -0.5 * np.dot(np.dot((y - mu).T, np.linalg.inv(Sigma)), (y - mu))\n",
    "    \n",
    "    return prefactor * np.exp(exponent)\n",
    "\n",
    "def negative_log_likelihood_state_space_multi(params, data, ksi0, P0, R = 0):\n",
    "    '''Method that calculates the negative log likelihood of a multivariate Kalman Filter'''\n",
    "    \n",
    "    # Unpack parameters\n",
    "    f0, f1, f2, f3, h1, h2, h3, q1, q2, q3 = params\n",
    "    \n",
    "    Q = np.array([[1,0,0,0], [0,q1,0,0], [0,0,q2,0], [0,0,0,q3]])\n",
    "    F = np.array([[f0,0,0,0], [0,f1,0,0], [0,0,f2,0], [0,0,0,f3]])\n",
    "    H = np.array([[h1,h2,h3], [1,0,0], [0,1,0], [0,0,1]])\n",
    "    \n",
    "    # Run Kalman Filter to get ksi and P\n",
    "    _, _, predicted_ksi, predicted_P = KF_LL_multi(Q, F, H, data, ksi0, P0)\n",
    "    \n",
    "    # Calculate log likelihood\n",
    "    log_likelihoods = list()\n",
    "    \n",
    "    for ksi, P, y in zip(predicted_ksi, predicted_P, data):\n",
    "        Sigma = H.T @ P @ H + R\n",
    "        mu = H.T @ ksi\n",
    "        if np.linalg.det(Sigma) <= 0: print(np.linalg.det(Sigma))\n",
    "        #LL = np.log(max(multivariate_normal_pdf(y, mu, Sigma), 10 ** -5))\n",
    "        LL = -0.5 * 4 * np.log(2*math.pi) - 0.5*math.log(max(np.linalg.det(Sigma), 10 ** -5)) - 0.5 * (y - mu).T @ np.linalg.inv(Sigma) @ (y - mu)\n",
    "        log_likelihoods.append(LL)\n",
    "    \n",
    "    return -1*sum(log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "y = list()\n",
    "for t in range(len(train_data_demean[\"PCE\"])): \n",
    "    y.append(np.array([[train_data_demean[\"PCE\"][t]], [train_data_demean[\"PAYEMS\"][t]], [train_data_demean[\"IPMAN\"][t]]]).reshape((3, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksi0 = np.array([[0], [0], [0], [0]])\n",
    "P0 = 10 ** 6 * np.eye(4)\n",
    "args = (y, ksi0, P0)\n",
    "\n",
    "# Inital values\n",
    "f0, f1, f2, f3, h1, h2, h3, q1, q2, q3 = (1, 0, 1, 1, 1, 1, 7, 10, 1, 1)\n",
    "x0 = (f0, f1, f2, f3, h1, h2, h3, q1, q2, q3)\n",
    "\n",
    "mle = optimize.minimize(negative_log_likelihood_state_space_multi, x0=x0, args=args, method='Nelder-Mead', options = {'maxiter': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_space_em(F0, H0, Q0, R0, y, ksi0, P0, fixed=[], niter = None, stop_if_small_change = None):\n",
    "    '''Method that performs a state space EM algorithm'''\n",
    "    \n",
    "    # Initalize parameters\n",
    "    F, H, Q, R = F0, H0, Q0, R0\n",
    "    \n",
    "    y_one_extra = [np.array([[0], [0], [0]])] + y\n",
    "    \n",
    "    iter = 0\n",
    "    while True:\n",
    "    \n",
    "        # Run Hamilton filter \n",
    "        ksi, P, pred_ksi, pred_P = KF_LL_multi(Q = Q, F = F, H = H, R = R, y = y, ksi0 = ksi0, P0 = P0)\n",
    "        \n",
    "        # Run Hamilton smoother\n",
    "        smoothed_ksi, smoothed_P, cross_P = kalman_smoother(ksi, P, pred_ksi, pred_P, F)\n",
    "        \n",
    "        T = len(ksi)\n",
    "        \n",
    "        # Update F, H, Q and R\n",
    "        F_old, H_old, Q_old, R_old = F, H, Q, R\n",
    "        \n",
    "        if not 'F' in fixed:\n",
    "            F_first_part = [smoothed_ksi[t]@smoothed_ksi[t-1].T + cross_P[t] for t in range(1,T+1)]\n",
    "            F_second_part = [smoothed_ksi[t]@smoothed_ksi[t].T + smoothed_P[t] for t in range(T)]\n",
    "            F = (sum(F_first_part)) @ np.linalg.inv(sum(F_second_part))\n",
    "        \n",
    "        if not 'H' in fixed:\n",
    "            H_first_part = [y[t]@smoothed_ksi[t].T for t in range(1,T+1)]\n",
    "            H = (sum(H_first_part)) @ np.linalg.inv(sum(F_second_part))\n",
    "        \n",
    "        if not 'Q' in fixed:\n",
    "            Q_first_part = [smoothed_ksi[t]@smoothed_ksi[t].T + smoothed_P[t] - F@(smoothed_ksi[t-1]@smoothed_ksi[t].T + cross_P[t])\n",
    "                            - (smoothed_ksi[t]@smoothed_ksi[t].T)@F.T + F@(smoothed_ksi[t-1]@smoothed_ksi[t-1].T + smoothed_P[t-1])@F.T for t in range(1, T+1)]\n",
    "            Q = 1 / T * sum(Q_first_part)\n",
    "            Q = (Q + Q.T) / 2\n",
    "        \n",
    "        if not 'R' in fixed:\n",
    "            R_first_part = [y_one_extra[t]@y_one_extra[t].T - H.T@smoothed_ksi[t]@y_one_extra[t].T - y_one_extra[t]@smoothed_ksi[t].T@H + H.T@(smoothed_ksi[t]@smoothed_ksi[t].T + smoothed_P[t]) for t in range(1, T+1)]\n",
    "            R = 1 / T * sum(R_first_part)\n",
    "            R = (R + R.T) / 2\n",
    "        \n",
    "        change = abs(np.sum(F_old - F)) + abs(np.sum(H_old - H)) + abs(np.sum(Q_old - Q)) + abs(np.sum(R_old - R))\n",
    "        \n",
    "        # Stop if condition is met\n",
    "        if not niter is None:\n",
    "            iter += 1\n",
    "            if iter >= niter:\n",
    "                break\n",
    "        \n",
    "        if not stop_if_small_change is None:\n",
    "            if change < stop_if_small_change:\n",
    "                break\n",
    "        \n",
    "    return F, H, Q, R, negative_log_likelihood_state_space_multi_2(Q = Q, F = F, H = H, data=y, ksi0=ksi0, P0=P0, R = R)\n",
    "    \n",
    "def kalman_smoother(ksi, P, pred_ksi, pred_P, F):\n",
    "    '''Method that performs the Kalman smoothing algorithm'''\n",
    "    \n",
    "    # Get length\n",
    "    T = len(ksi)\n",
    "    \n",
    "    # Calculate the smoothed ksi, smoothed P and smoothed cross-sectional P\n",
    "    smoothed_ksi = [ksi[-1]] * (T + 1)\n",
    "    smoothed_P = [P[-1]] * (T + 1)\n",
    "    cross_P = [P[-1]] * (T + 1)\n",
    "    \n",
    "    for t in range(T-1, -1, -1):\n",
    "        \n",
    "        smoothed_ksi[t] = ksi[t] + P[t] @ F.T @ np.linalg.inv(pred_P[t]) @ (smoothed_ksi[t+1] - pred_ksi[t])\n",
    "        \n",
    "        smoothed_P[t] = P[t] - P[t] @ F.T @ np.linalg.inv(pred_P[t]) @ (pred_P[t] - smoothed_P[t+1]) @ np.linalg.inv(pred_P[t]) @ F @ P[t]\n",
    "        \n",
    "        cross_P[t+1] = smoothed_P[t+1] @ np.linalg.inv(pred_P[t]) @ F @ P[t]\n",
    "        \n",
    "    return smoothed_ksi, smoothed_P, cross_P\n",
    "\n",
    "def negative_log_likelihood_state_space_multi_2(Q, F, H, data, ksi0, P0, R = 0):\n",
    "    '''Method that calculates the negative log likelihood of a multivariate Kalman Filter'''\n",
    "    \n",
    "    # Run Kalman Filter to get ksi and P\n",
    "    _, _, predicted_ksi, predicted_P = KF_LL_multi(Q = Q, F = F, H = H, R = R, y = data, ksi0 = ksi0, P0 = P0)\n",
    "    \n",
    "    # Calculate log likelihood\n",
    "    log_likelihoods = list()\n",
    "    \n",
    "    for ksi, P, y in zip(predicted_ksi, predicted_P, data):\n",
    "        \n",
    "        Sigma = H.T @ P @ H + R\n",
    "        mu = H.T @ ksi\n",
    "        \n",
    "        if np.linalg.det(Sigma) <= 0: print(np.linalg.det(Sigma))\n",
    "        #LL = np.log(max(multivariate_normal_pdf(y, mu, Sigma), 10 ** -5))\n",
    "        LL = -0.5 * 4 * np.log(2*math.pi) - 0.5*math.log(max(np.linalg.det(Sigma), 10 ** -5)) - 0.5 * (y - mu).T @ np.linalg.inv(Sigma) @ (y - mu)\n",
    "        log_likelihoods.append(LL)\n",
    "    \n",
    "    return -1*sum(log_likelihoods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix of first differences\n",
    "y_fd = None\n",
    "for i in range(len(y[0])):\n",
    "    \n",
    "    y_i_fd = list()\n",
    "    for t in range(1, len(y)):\n",
    "        y_i_fd.append(y[t][i] - y[t-1][i])\n",
    "    \n",
    "    if y_fd is None:\n",
    "        y_fd = np.array(y_i_fd).T\n",
    "    else:\n",
    "        y_fd = np.vstack([y_fd, np.array(y_i_fd).T])\n",
    "\n",
    "# Initial parameters\n",
    "F0 = 0.95 * np.eye(3)\n",
    "H0 = np.eye(3)\n",
    "R0 = 0.2 * np.cov(y_fd)\n",
    "Q0 = 0.5 * np.cov(y_fd)\n",
    "\n",
    "ksi0 = np.array([[0], [0], [0]])\n",
    "P0 = 10 ** 6 * np.eye(3)\n",
    "\n",
    "F20, H20, Q20, R20, ll20 = state_space_em(F0, H0, Q0, R0, y=y, ksi0=ksi0, P0=P0, fixed = ['H'], niter=2)\n",
    "F, H, Q, R, ll = state_space_em(F0, H0, Q0, R0, y=y, ksi0=ksi0, P0=P0, fixed = ['H'], niter=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F)\n",
    "print(H)\n",
    "print(Q)\n",
    "print(R)\n",
    "\n",
    "print(P0)\n",
    "\n",
    "print(ll20)\n",
    "print(ll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
