{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Management - Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\pelpi\\\\Documents\\\\VSCode repositories\\\\portfolio-management\\\\src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General\n",
    "import os # change working directory\n",
    "import pandas as pd # dataframes\n",
    "import numpy as np # numpy\n",
    "import math # square root\n",
    "from matplotlib import pyplot as plt # plot figures\n",
    "import copy # make actual copies\n",
    "\n",
    "# Question a)\n",
    "from sklearn.decomposition import FactorAnalysis # factor analysis\n",
    "from scipy.stats import jarque_bera # jarque-bera statistic for normality\n",
    "from statsmodels.regression.linear_model import OLS # OLS\n",
    "\n",
    "# Simulation\n",
    "from scipy.stats import lognorm # lognormal distribution\n",
    "from scipy.stats import gamma # gamma distribution\n",
    "from scipy.stats import norm # normal distributin\n",
    "from typing import Callable # type hinting functions\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:/Users/pelpi/Documents/VSCode repositories/portfolio-management/src')\n",
    "\n",
    "# Load data on returns of 550 stocks between 2010 and 2016, and risk free rate\n",
    "os.chdir(\"..\") # Change workin directory to parent\n",
    "return_df = pd.read_csv('data\\RET.csv')\n",
    "rf_df = pd.read_csv('data\\F-F_Research_Data_Factors_daily.csv')\n",
    "rf_df.rename({'Unnamed: 0': 'DATE'}, axis=1, inplace=True)\n",
    "os.chdir(os.getcwd() + '\\src') # Change working directory back\n",
    "\n",
    "# Convert strings of dates to datetime objects\n",
    "return_df['DATE'] = pd.to_datetime(return_df['DATE'])\n",
    "rf_df['DATE'] = pd.to_datetime(rf_df['DATE'], format = '%Y%m%d')\n",
    "\n",
    "# Change Fama-French to percentages\n",
    "rf_df[rf_df.columns[1:]] = rf_df[rf_df.columns[1:]]/ 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of what the data looks like\n",
    "return_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the risk free rate at the start of the stock return sample\n",
    "rf_df[rf_df['DATE'] > return_df.iloc[0]['DATE']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract the risk free return from the returns\n",
    "def substract_rf(returns_df, rf_df, date_col, rf_col):\n",
    "    # Merge dataframes based on the 'date' column\n",
    "    merged_df = pd.merge(returns_df, rf_df[[date_col, rf_col]], on=date_col, how='inner')\n",
    "\n",
    "    # Subtract risk-free rate from each stock return\n",
    "    for stock_col in returns_df.columns[1:]:  # Assuming the first column is 'date'\n",
    "        merged_df[stock_col] = merged_df[stock_col] - merged_df[rf_col]\n",
    "\n",
    "    # Drop the 'risk_free_rate' column if you don't need it anymore\n",
    "    merged_df = merged_df.drop(rf_col, axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "df = substract_rf(return_df, rf_df, 'DATE', 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question a) Fit Factor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive factors \n",
    "K = 1 # Number of latent factors\n",
    "factor_model = FactorAnalysis(n_components=K)\n",
    "factor_model.fit(df.drop('DATE', axis=1).T) # Take transpose so that the factors differ per time instead of the stocks\n",
    "factors = factor_model.components_[0]\n",
    "\n",
    "# Obtain betas for all stocks\n",
    "beta_dict_fa = dict()\n",
    "for stock in df.columns[1:]:\n",
    "    \n",
    "    # Regress the factors on the returns to obtain beta, store in a dictionary\n",
    "    beta = OLS(df[stock], factors).fit().params[0]\n",
    "    beta_dict_fa[stock] = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quick_distribution_check(data, bins = 100, title='Distribution Check'):\n",
    "    # Plot factors to see whether normality assumption makes sense\n",
    "    plt.hist(data, density=True, bins=bins, edgecolor='black', alpha=0.7);\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Density')\n",
    "    print(f'Jarque-Bera: {jarque_bera(data).statistic:0.2f}')\n",
    "\n",
    "    # Find and print the mean and variance\n",
    "    data_mean = data.mean()\n",
    "    data_std = data.std()\n",
    "    print(f'Mean: {data_mean}, Std: {data_std}')\n",
    "    \n",
    "    return data_mean, data_std\n",
    "\n",
    "# Plot histogram and automatically estimate the normal parameters\n",
    "factor_mean, factor_std = quick_distribution_check(factors,\n",
    "                                                   title='Histogram and theoretical distribution of factors')\n",
    "\n",
    "# Add theoretical normal histogram\n",
    "def add_theoretical_histogram(func, *args, **kwargs):\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = func(x, *args, **kwargs)\n",
    "    plt.plot(x, p, 'k',\n",
    "             linewidth=2,\n",
    "             color='red',\n",
    "             label='Theoretical -- Distribution')\n",
    "\n",
    "# Add the theoretical histogram under normality\n",
    "add_theoretical_histogram(norm.pdf, factor_mean, factor_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question a*) Fit Fama-French market factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get information from factor over entire sample (1926-07-01 - 2023-09-29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_mean, mkt_std = quick_distribution_check(rf_df['Mkt-RF'],\n",
    "                                             bins=100,\n",
    "                                             title='Histogram and theoretical distribution of factors')\n",
    "add_theoretical_histogram(norm.pdf, mkt_mean, mkt_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes on the date column\n",
    "df_merged = pd.merge(df, rf_df[['DATE', 'Mkt-RF']], on='DATE', how='inner')\n",
    "\n",
    "# Obtain betas for all stocks\n",
    "beta_dict_ff = dict()\n",
    "std_dict_ff = dict()\n",
    "for stock in df.columns[1:]:\n",
    "    \n",
    "    # Regress the factors on the returns to obtain beta, store in a dictionary\n",
    "    model = OLS(df_merged[stock], df_merged['Mkt-RF']).fit()\n",
    "    beta_dict_ff[stock] = model.params[0]\n",
    "    \n",
    "    # Save the scale of the model \n",
    "    std_dict_ff[stock] = math.sqrt(model.scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question b) Optimal Sharpe ratio under factor analysis factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_sharpe = (factor_mean) / factor_std\n",
    "print(optimal_sharpe)\n",
    "\n",
    "# Negative Sharpe, so the option to plot a histogram of the cumulative returns\n",
    "quick_distribution_check(df[df.columns[1:]].sum(axis=1), bins = 100);\n",
    "#quick_distribution_check((1+df[df.columns[1:]]).product(axis=1), bins = 100); # Gives very strange results, so these returns probably are additive anyway??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question b*) Optimal Sharpe ratio under Fama-French market factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mkt_mean / mkt_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of betas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "beta_dict = beta_dict_ff # _ff for Fama-Fench, _fa for factor analysis\n",
    "betas = np.array(list(beta_dict.values()))\n",
    "quick_distribution_check(betas,\n",
    "                         bins=50,\n",
    "                         title='Histogram and theoretical distribution of betas')\n",
    "\n",
    "# Estimate gamma parameters\n",
    "beta_params = gamma.fit(betas)\n",
    "print(beta_params)\n",
    "\n",
    "# Plot theoretical histogram\n",
    "add_theoretical_histogram(gamma.pdf, *beta_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of error standard deviations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "quick_distribution_check(np.sqrt(factor_model.noise_variance_))\n",
    "\n",
    "# Estimate parameters\n",
    "std_params_fa = lognorm.fit(np.sqrt(factor_model.noise_variance_))\n",
    "print(std_params_fa)\n",
    "\n",
    "# Add theoretical histogram\n",
    "add_theoretical_histogram(lognorm.pdf, *std_params_fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fama-French factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_distribution_check(pd.Series(std_dict_ff.values()),\n",
    "                         bins=50,\n",
    "                         title='Histogram and theoretical distribution of std. devs.')\n",
    "\n",
    "# Estimate parameters\n",
    "std_params_ff = lognorm.fit(np.sqrt(factor_model.noise_variance_))\n",
    "print(std_params_ff)\n",
    "\n",
    "# Add theoretical histogram\n",
    "add_theoretical_histogram(lognorm.pdf, *std_params_ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if betas and standard deviations are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(beta_dict_ff.values(), std_dict_ff.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_drawer(function, *args, **kwargs):\n",
    "    '''Method that wraps around a given function with given parameters to turn it into a simple callable'''\n",
    "    \n",
    "    def drawer():\n",
    "        return function(*args, **kwargs)\n",
    "    \n",
    "    return drawer\n",
    "\n",
    "class MarketSimulator:\n",
    "    '''Class that creates a simulated market that is fully determined by a one factor model'''\n",
    "    \n",
    "    def __init__(self, beta_drawer: Callable, std_drawer: Callable, factor_drawer: Callable):\n",
    "        self.beta_drawer = beta_drawer\n",
    "        self.std_drawer = std_drawer\n",
    "        self.factor_drawer = factor_drawer\n",
    "    \n",
    "    # Used for questions on simulated data    \n",
    "    def simulate(self, n_assets, n_observations):\n",
    "        '''Method that simulates a MarketSimulator for a given number of assets and observations'''\n",
    "\n",
    "        # Draw the betas and factors\n",
    "        betas = np.array([self.beta_drawer() for i in range(n_assets)])\n",
    "        stds = np.array([abs(self.std_drawer()) for i in range(n_assets)])\n",
    "        factors = np.array([self.factor_drawer() for t in range(n_observations)])\n",
    "        \n",
    "        # Create a matrix of the simulated returns\n",
    "        Betas = np.vstack([betas] * n_observations)\n",
    "        Factors = np.vstack([factors] * n_assets).T\n",
    "        Errors = np.random.normal(0, stds, (n_observations, n_assets))\n",
    "        \n",
    "        simulated_returns = np.multiply(Betas, Factors) + Errors\n",
    "        \n",
    "        # Store the simulated returns in a dataframe\n",
    "        cols = [f'{beta:0.2f}' for beta in betas]\n",
    "        simulated_returns_df = pd.DataFrame(simulated_returns, columns = cols)\n",
    "        \n",
    "        # Return the dataframe as a MarketSimulation\n",
    "        simulation = MarketSimulation(simulated_returns_df)\n",
    "        simulation.betas = betas\n",
    "        simulation.stds = stds\n",
    "        simulation.factors = factors\n",
    "        simulation.n_observations = n_observations\n",
    "        \n",
    "        return simulation\n",
    "        \n",
    "class MarketSimulation(pd.DataFrame):\n",
    "    '''Extension of a pandas Dataframe that contains the results of\n",
    "    a market simulation and useful methods to analyze portfolio\n",
    "    strategy performances'''\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # use the __init__ method from DataFrame to ensure\n",
    "        # that we're inheriting the correct behavior\n",
    "        super(MarketSimulation, self).__init__(*args, **kwargs)\n",
    "        self.betas = None\n",
    "        self.stds = None\n",
    "        self.factors = None\n",
    "        self.n_observations = None\n",
    "        \n",
    "    @property\n",
    "    # this method is makes it so our methods return an instance\n",
    "    # of MarketSimulation, instead of a regular DataFrame\n",
    "    def _constructor(self):\n",
    "        return MarketSimulation\n",
    "    \n",
    "    # Used for question 2c)\n",
    "    def get_equally_weighted_performance(self, in_sample_fraction, stop_fraction = 1, return_returns = False):\n",
    "        '''Method that gets the Sharpe ratio and turnover of an equally weighted portfolio for a given in_sample_fraction of observations'''\n",
    "        \n",
    "        # Get the out-of-sample length\n",
    "        out_of_sample_length = math.ceil((1-in_sample_fraction) * self.n_observations)\n",
    "        \n",
    "        # Set up the easy weights matrix\n",
    "        weights = np.ones((out_of_sample_length, len(self.betas))) / len(self.betas)\n",
    "        \n",
    "        # Return the performance\n",
    "        return self.get_performance(weights, in_sample_fraction, stop_fraction, return_returns)\n",
    "    \n",
    "    # Used for a lot of questions\n",
    "    def get_general_performance(self, weights_function, estimation_window, in_sample_fraction, stop_fraction, return_returns=False):\n",
    "        '''Method that gets the Sharpe ratio and turnover of for a given weights function for a given in_sample_fraction of observations'''\n",
    "        \n",
    "        # Get the out-of-sample length\n",
    "        out_of_sample_length = math.ceil((1-in_sample_fraction) * self.n_observations)\n",
    "        \n",
    "        # Set up weights matrix\n",
    "        weights = np.ones((out_of_sample_length, len(self.betas)))\n",
    "        \n",
    "        # Set the index where the out of sample period begins\n",
    "        begin_index = math.floor(self.n_observations * in_sample_fraction)\n",
    "        \n",
    "        for t in range(out_of_sample_length):\n",
    "\n",
    "            # Utilize last estimation window rows to determine sample covariance matrix\n",
    "            used_returns = self[begin_index + t - estimation_window:(begin_index + t)]\n",
    "            inv_cov = np.linalg.inv(np.cov(used_returns.to_numpy().T)) # Transpose so the covariance is calculated for the stocks instead of the dates\n",
    "            mu = used_returns.mean().values\n",
    "            \n",
    "            # Add row to weights matrix using the provided weights function\n",
    "            weights[t] = weights_function(inv_cov, mu)\n",
    "            \n",
    "        # Return the performance\n",
    "        return self.get_performance(weights, in_sample_fraction, stop_fraction, return_returns)\n",
    "    \n",
    "    # Used for question d)\n",
    "    def tangency_weights(self, inv_cov, mu):\n",
    "        '''Method that calculates the tangency weights using the inverse sample covariance matrix and mu'''\n",
    "        return inv_cov @ mu / (np.ones(len(self.betas)).T @ inv_cov @ mu)\n",
    "    \n",
    "    def get_tangency_performance(self, estimation_window, in_sample_fraction, stop_fraction = 1, return_returns=False):\n",
    "        '''Method that gets the Sharpe ratio and turnover of a tangency portfolio for a given in_sample_fraction of observations'''\n",
    "        \n",
    "        return self.get_general_performance(self.tangency_weights, estimation_window, in_sample_fraction, stop_fraction, return_returns)\n",
    "    \n",
    "    # Used for question e)\n",
    "    def get_tangency_performance_is(self, begin_fraction, end_fraction):\n",
    "        '''Methd that obtains the in sample performance of a tangency portfolio'''\n",
    "        \n",
    "        # Set begin and end indices\n",
    "        begin_index = math.floor(self.n_observations * begin_fraction)\n",
    "        end_index = math.floor(self.n_observations * end_fraction)\n",
    "        \n",
    "        # Calculate the weights that are used\n",
    "        used_returns = self[begin_index:end_index]\n",
    "        inv_cov = np.linalg.inv(np.cov(used_returns.to_numpy().T)) # Transpose so the covariance is calculated for the stocks instead of the dates\n",
    "        mu = used_returns.mean().values\n",
    "    \n",
    "        weights_row = inv_cov @ mu / (np.ones(len(self.betas)).T @ inv_cov @ mu)\n",
    "        weights = np.vstack([weights_row] * (end_index - begin_index))\n",
    "        \n",
    "        # Return the performance\n",
    "        return self.get_performance(weights, begin_fraction, end_fraction)\n",
    "    \n",
    "    # Used for question f)\n",
    "    def unconstrained_mv_weights(self, inv_cov, _):\n",
    "        '''Method that calculates the unconstrained minimum variance weights using the inverse sample covariance matrix and mu'''\n",
    "        iota = np.ones(len(self.betas))\n",
    "        \n",
    "        return inv_cov @ iota / (iota.T @ inv_cov @ iota)\n",
    "    \n",
    "    def get_unconstrained_mv_performance(self, estimation_window, in_sample_fraction, stop_fraction = 1, return_returns=False):\n",
    "        '''Method that gets the Sharpe ratio and turnover of a tangency portfolio for a given in_sample_fraction of observations'''\n",
    "        \n",
    "        return self.get_general_performance(self.unconstrained_mv_weights, estimation_window, in_sample_fraction, stop_fraction, return_returns)\n",
    "    \n",
    "    # Used for question g)\n",
    "    def constrained_mv_weights(self, inv_cov, mu):\n",
    "        '''Method that calculates the constrained minimum variance weights using the inverse sample covariance matrix and mu'''\n",
    "        \n",
    "        # First calculate unconstrained weights\n",
    "        unconstrained_weights = self.unconstrained_mv_weights(inv_cov, mu)\n",
    "        \n",
    "        # Force the negative weights to be zero\n",
    "        b = np.array([1 if weight > 0 else 0 for weight in unconstrained_weights])\n",
    "                    \n",
    "        return inv_cov @ b / (b.T @ inv_cov @ b)\n",
    "    \n",
    "    def get_constrained_mv_performance(self, estimation_window, in_sample_fraction, stop_fraction = 1, return_returns=False):\n",
    "        '''Method that gets the Sharpe ratio and turnover of a tangency portfolio for a given in_sample_fraction of observations'''\n",
    "        \n",
    "        return self.get_general_performance(self.constrained_mv_weights, estimation_window, in_sample_fraction, stop_fraction, return_returns)\n",
    "    \n",
    "    # Used for question h)\n",
    "    def get_oc_weights(self, inv_cov, mu):\n",
    "        '''Method that calculates the optimal constrained weights using the inverse sample covariance matrix and mu'''\n",
    "\n",
    "        # Calculate the weights of relevant portfolios\n",
    "        weights_1oN = np.ones(len(mu)) / len(mu)\n",
    "        weights_mv = self.unconstrained_mv_weights(inv_cov, mu)\n",
    "        weights_tan = self.tangency_weights(inv_cov, mu)\n",
    "        \n",
    "        # Caluclate the implied target returns\n",
    "        mu_1oN = mu.T @ weights_1oN\n",
    "        mu_mv = mu.T @ weights_mv\n",
    "        mu_tan = mu.T @ weights_tan\n",
    "        \n",
    "        # Calculate and return the weighted return\n",
    "        weight = (mu_1oN - mu_mv) / (mu_tan - mu_mv)\n",
    "        \n",
    "        return weight * weights_tan + weights_mv * (1 - weight)\n",
    "    \n",
    "    def get_oc_performance(self, estimation_window, in_sample_fraction, stop_fraction = 1, return_returns=False):\n",
    "        '''Method that gets the Sharpe ratio and turnover of a tangency portfolio for a given in_sample_fraction of observations'''\n",
    "        \n",
    "        return self.get_general_performance(self.get_oc_weights, estimation_window, in_sample_fraction, stop_fraction, return_returns)\n",
    "    \n",
    "    # Used for a lot of questions\n",
    "    def get_performance(self, weights, in_sample_fraction, stop_fraction, return_returns=False):\n",
    "        '''Method that obtains the Sharpe ratio and turnover of a given set of weights and in sample fraction of observations'''\n",
    "        \n",
    "        # Set the index where the out of sample period begins\n",
    "        begin_index = math.floor(self.n_observations * in_sample_fraction)\n",
    "        stop_index = math.floor(self.n_observations * stop_fraction)\n",
    "\n",
    "        if len(weights) != stop_index - begin_index:\n",
    "            raise ValueError(\"The weights do not have the correct length\")\n",
    "        \n",
    "        # Get an array of returns at each time\n",
    "        returns = np.array([])\n",
    "        \n",
    "        for i in range(len(self[begin_index:stop_index])):\n",
    "            \n",
    "            row=self.iloc[i]\n",
    "            row_array = row.to_numpy()\n",
    "            \n",
    "            returns = np.append(returns, row_array @ weights[i].T) # Add the return\n",
    "        \n",
    "        # Calculate the sharpe ratio\n",
    "        sharpe_ratio = returns.mean() / returns.std()\n",
    "        \n",
    "        # Calculate the turnover\n",
    "\n",
    "        ## Calculate the portfolio weights at the end of the period\n",
    "        weights_end = weights * (1 + self[begin_index:stop_index].to_numpy())\n",
    "\n",
    "        ## Calculate the total portfolio value at the end of the period\n",
    "        total_portfolio_value = np.sum(weights_end, axis=1)\n",
    "\n",
    "        ## Normalize the portfolio weights to ensure they sum up to 1 at the end of the period\n",
    "        weights_end_normalized = weights_end / total_portfolio_value[:, np.newaxis]\n",
    "        \n",
    "        ## get turnover\n",
    "        turnover = np.sum(np.abs(weights_end_normalized[:-1] - weights[1:])) / len(weights)\n",
    "        \n",
    "        if not return_returns:\n",
    "            return sharpe_ratio, turnover\n",
    "        else:\n",
    "            return sharpe_ratio, turnover, returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use\n",
    "std_params = std_params_ff\n",
    "\n",
    "# Callables used to draw the betas and factors\n",
    "beta_drawer = make_drawer(gamma.rvs, *beta_params)\n",
    "std_drawer = make_drawer(lognorm.rvs, *std_params)\n",
    "factor_drawer = make_drawer(np.random.normal, mkt_mean, mkt_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(1913)\n",
    "\n",
    "# Simulate\n",
    "n_observations = 20000\n",
    "N = (10, 100)\n",
    "\n",
    "simulations = dict()\n",
    "\n",
    "for n in N:\n",
    "    simulator = MarketSimulator(beta_drawer, std_drawer, factor_drawer)\n",
    "    simulations[n] = simulator.simulate(n_assets = n, n_observations = n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the simulated MarketSimulation\n",
    "simulations[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations[10].get_equally_weighted_performance(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations[10].get_tangency_performance(120, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations[10].get_tangency_performance_is(0, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations[10].get_unconstrained_mv_performance(120, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations[10].get_constrained_mv_performance(120, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations[10].get_oc_performance(120, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe and turnover table (Can take a long time)\n",
    "\n",
    "N = [10, 100]\n",
    "M = [120, 240, 3600]\n",
    "split_ratio = 0.6\n",
    "portfolios = ['1/N', 'Tangency out of sample', 'Tangency in sample', 'Unconstrained minmum variance', 'Constrained minimum variance', 'Optimal constrained']\n",
    "\n",
    "# Set up Dataframes with Sharpe ratios and turnovers\n",
    "sharpe_df = pd.DataFrame(columns=[str(m) for m in M])\n",
    "sharpe_df['portfolio'] = [f'{portfolio}_{n}' for portfolio in portfolios for n in N]\n",
    "sharpe_df.set_index('portfolio', inplace=True, drop=True)\n",
    "\n",
    "turnover_df = copy.copy(sharpe_df)\n",
    "\n",
    "for n in N:\n",
    "    \n",
    "    for portfolio in [portfolios[4]]:\n",
    "        \n",
    "        print(f'Now at n: {n}, portfolio: {portfolio}')\n",
    "        \n",
    "        if portfolio == '1/N':\n",
    "            sharpe_turnover = {str(m): simulations[n].get_equally_weighted_performance(split_ratio) for m in M}\n",
    "    \n",
    "        elif portfolio == 'Tangency out of sample':\n",
    "        \n",
    "            sharpe_turnover = {str(m): simulations[n].get_tangency_performance(m, split_ratio) for m in M}\n",
    "\n",
    "        elif portfolio == 'Tangency in sample':\n",
    "        \n",
    "            sharpe_turnover = {str(m): simulations[n].get_tangency_performance_is(0, split_ratio) for m in M}\n",
    "            \n",
    "        elif portfolio == 'Unconstrained minmum variance':\n",
    "        \n",
    "            sharpe_turnover = {str(m): simulations[n].get_unconstrained_mv_performance(m, split_ratio) for m in M}\n",
    "            \n",
    "        elif portfolio == 'Constrained minimum variance':\n",
    "        \n",
    "            sharpe_turnover = {str(m): simulations[n].get_constrained_mv_performance(m, split_ratio) for m in M}\n",
    "            \n",
    "        elif portfolio == 'Optimal constrained':\n",
    "        \n",
    "            sharpe_turnover = {str(m): simulations[n].get_oc_performance(m, split_ratio) for m in M}\n",
    "\n",
    "        sharpe_row = {str(m): sharpe_turnover[str(m)][0] for m in M}\n",
    "        turnover_row = {str(m): sharpe_turnover[str(m)][1] for m in M}\n",
    "        \n",
    "        # Change row\n",
    "        sharpe_df.loc[f'{portfolio}_{n}'] = sharpe_row\n",
    "        turnover_df.loc[f'{portfolio}_{n}'] = turnover_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframes if you want to\n",
    "turnover_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make excel file to use as Matlab input for the Sharpe significance tests\n",
    "\n",
    "returns1a = simulations[10].get_oc_performance(120, 0.6, return_returns = True)[2]\n",
    "returns1b = simulations[10].get_equally_weighted_performance(0.6, return_returns = True)[2]\n",
    "returns2a = simulations[10].get_oc_performance(240, 0.6, return_returns = True)[2]\n",
    "returns2b = simulations[10].get_equally_weighted_performance(0.6, return_returns = True)[2]\n",
    "returns3a = simulations[10].get_oc_performance(3600, 0.6, return_returns = True)[2]\n",
    "returns3b = simulations[10].get_equally_weighted_performance(0.6, return_returns = True)[2]\n",
    "\n",
    "returns4a = simulations[100].get_oc_performance(120, 0.6, return_returns = True)[2]\n",
    "returns4b = simulations[100].get_equally_weighted_performance(0.6, return_returns = True)[2]\n",
    "returns5a = simulations[100].get_oc_performance(240, 0.6, return_returns = True)[2]\n",
    "returns5b = simulations[100].get_equally_weighted_performance(0.6, return_returns = True)[2]\n",
    "returns6a = simulations[100].get_oc_performance(3600, 0.6, return_returns = True)[2]\n",
    "returns6b = simulations[100].get_equally_weighted_performance(0.6, return_returns = True)[2]\n",
    "df = pd.DataFrame({\n",
    "    'returns1a': returns1a,\n",
    "    'returns1b': returns1b,\n",
    "    'returns2a': returns2a,\n",
    "    'returns2b': returns2b,\n",
    "    'returns3a': returns3a,\n",
    "    'returns3b': returns3b,\n",
    "    'returns4a': returns4a,\n",
    "    'returns4b': returns4b,\n",
    "    'returns5a': returns5a,\n",
    "    'returns5b': returns5b,\n",
    "    'returns6a': returns6a,\n",
    "    'returns6b': returns6b\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel\n",
    "df.to_excel('output_file.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
